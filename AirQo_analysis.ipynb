{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, preprocessing, models, layers\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('src/data/airquality-dataset/sample_dataset.csv', index_col=0, chunksize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50 entries, 0 to 49\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   channel_id  50 non-null     int64  \n",
      " 1   pm2_5       50 non-null     float64\n",
      " 2   pm10        50 non-null     float64\n",
      " 3   s2_pm2_5    50 non-null     float64\n",
      " 4   s2_pm10     50 non-null     float64\n",
      " 5   Site        50 non-null     object \n",
      " 6   TimeStamp   50 non-null     object \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "Data.get_chunk().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = {'channel_id' : 'uint32',\n",
    "            'pm2_5' : 'float32',\n",
    "            'pm10' : 'float32',\n",
    "            's2_pm2_5' : 'float32',\n",
    "            's2_pm10' : 'float32',\n",
    "            'Site' : 'str',\n",
    "            'TimeStamp' : 'str'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataPath, dataType: dict) -> pd.core.frame.DataFrame:\n",
    "    data = pd.read_csv(dataPath, dtype=dataType, index_col=0)\n",
    "    data = data.drop_duplicates(ignore_index=True)\n",
    "    data['TimeStamp'] = pd.to_datetime(data['TimeStamp'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usman/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = load_data(dataPath='src/data/airquality-dataset/sample_dataset.csv', dataType=dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelSite = dict(zip(data['channel_id'].unique(), data['Site'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteGroups = data.groupby('channel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in siteGroups.groups:\n",
    "#     if not os.path.exists('data_group'):\n",
    "#         os.makedirs('data_group')\n",
    "#     siteGroups.get_group(x).to_csv(f'data_group/{x}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readChannel(channelId: int, dataPath='src/data/data_group/') -> pd.core.frame.DataFrame:\n",
    "    path = dataPath + str(channelId) + '.csv'\n",
    "    channelData = pd.read_csv(path, index_col=0, parse_dates=['TimeStamp'])\n",
    "    return channelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one = readChannel(channelId=list(channelSite.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one = readChannel(channelId=list(channelSite.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one_new.index.weekofyear.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one_new2 = preprocess(channel_one, ['hour', 'day', 'month', 'day_of_week', 'week_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    df = df.drop(labels='channel_id', axis=1).set_index(['TimeStamp']).resample('H').mean().fillna(method='ffill')\n",
    "    #df = df.drop(labels='channel_id', axis=1).groupby(pd.Grouper(key='TimeStamp', freq='1H')).mean().fillna(method='ffill')\n",
    "    df = df.assign(hour = df.index.hour,\n",
    "                   day = df.index.day,\n",
    "                   month = df.index.month,\n",
    "                   day_of_week = df.index.dayofweek,\n",
    "                   week_of_year = df.index.week)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_cyclical_features(df: pd.core.frame.DataFrame, col_name: list) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    \n",
    "    for time_col in col_name:\n",
    "        kwargs = {\n",
    "            f'sin_{time_col}' :lambda x: np.sin(2*np.pi*(x[time_col] - x[time_col].min()) / x[time_col].nunique()),\n",
    "            f'cos_{time_col}' :lambda x: np.cos(2*np.pi*(x[time_col] - x[time_col].min()) / x[time_col].nunique())    \n",
    "                 }\n",
    "        df_time = df.assign(**kwargs)[['sin_'+time_col, 'cos_'+time_col]]\n",
    "        \n",
    "        df = pd.concat([df, df_time], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def oneHotEncoding(df: pd.core.frame.DataFrame, col_name:list) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    return pd.get_dummies(data=df, columns=col_name, drop_first=True)\n",
    "\n",
    "def preprocess(df, col_list=['hour', 'day', 'month', 'day_of_week', 'week_of_year']):\n",
    "\n",
    "    df = getFeatures(df)\n",
    "    df = generate_cyclical_features(df, col_list)\n",
    "    df = oneHotEncoding(df, col_list)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=['pm2_5', 'pm10', 's2_pm2_5', 's2_pm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_one_new.resample('H').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "channel_one_new[:1000].drop('channel_id', axis=1).plot(subplots=True, layout=(2,2),\n",
    "                                                              figsize=(14,10), sharex=False, rot=45)\n",
    "plt.tight_layout(pad=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = TimeseriesGenerator(data=channel_one_new2.to_numpy(), targets=channel_one_new2['pm2_5'].to_numpy().reshape(-1,1), length=24, sampling_rate=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_0 = batch_data[0]\n",
    "x, y = batch_0\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one_new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_one_new2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = DDD[1]\n",
    "x1, y1 = batch_1\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataa = np.array([[i] for i in range(50)])\n",
    "targets = np.array([[i] for i in range(50)])\n",
    "data_gen = TimeseriesGenerator(dataa, targets,\n",
    "                               length=10, sampling_rate=2,\n",
    "                               batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeseriesGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(100, input_shape=(x.shape[1], x.shape[2]), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(batch_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './models/912223_NN_model.ckpt.data-00000-of-00001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YYY = model.evaluate(batch_data, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data[0][0].shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_model = models.Sequential([\n",
    "    layers.SimpleRNN(100, input_shape=(x.shape[1], x.shape[2]), dropout=0.5, recurrent_dropout=0.5),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='adam', loss='mse')\n",
    "rnn_model.fit(batch_data, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = models.Sequential([\n",
    "    layers.Bidirectional(layers.LSTM(100, return_sequences=True, recurrent_dropout=0.5), input_shape=(x.shape[1], x.shape[2])),\n",
    "    layers.Bidirectional(layers.LSTM(100, recurrent_dropout=0.5)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "lstm_model.fit(batch_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one.groupby(pd.Grouper(key='TimeStamp', freq='1H')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer, RobustScaler, QuantileTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    df = df.drop(labels='channel_id', axis=1).groupby(pd.Grouper(key='TimeStamp', freq='1H')).mean().fillna(method='ffill')\n",
    "    df = df.assign(hour = KK.index.hour,\n",
    "                   day = KK.index.day,\n",
    "                   month = KK.index.month,\n",
    "                   day_of_week = KK.index.dayofweek,\n",
    "                   week_of_year = KK.index.week)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_cyclical_features(df: pd.core.frame.DataFrame, col_name: list) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    \n",
    "    for time_col in col_name:\n",
    "        kwargs = {\n",
    "            f'sin_{time_col}' :lambda x: np.sin(2*np.pi*(x[time_col] - x[time_col].min()) / x[time_col].nunique()),\n",
    "            f'cos_{time_col}' :lambda x: np.cos(2*np.pi*(x[time_col] - x[time_col].min()) / x[time_col].nunique())    \n",
    "                 }\n",
    "        df_time = df.assign(**kwargs)[['sin_'+time_col, 'cos_'+time_col]]\n",
    "        \n",
    "        df = pd.concat([df, df_time], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def oneHotEncoding(df: pd.core.frame.DataFrame, col_name:list) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    return pd.get_dummies(data=df, columns=col_name, drop_first=True)\n",
    "    \n",
    "    \n",
    "def featureLabelSplit(df, target:list):\n",
    "    Y = df[target].to_numpy()\n",
    "    X = df.drop(columns=target).to_numpy()\n",
    "    return (X,Y)\n",
    "    \n",
    "def train_test_spliting(X , Y, test_ratio:float):\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=test_ratio, shuffle=False)\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(X, Y, scaler=\"standard\"):\n",
    "    scalers = {\n",
    "        \"minmax\": MinMaxScaler,\n",
    "        \"standard\": StandardScaler,\n",
    "        \"power\": PowerTransformer,\n",
    "        \"robust\": RobustScaler,\n",
    "        \"quantile\": QuantileTransformer\n",
    "    }\n",
    "    \n",
    "    scaler = scalers[scaler]()\n",
    "    X = scaler.fit_transform(X)\n",
    "    Y = scaler.fit_transform(Y)\n",
    "    \n",
    "    return scaler, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AA = getFeatures(channel_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB = generate_cyclical_features(AA, ['hour', 'day', 'month',\n",
    "       'day_of_week', 'week_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC = oneHotEncoding(BB, col_name=['hour', 'day', 'month','day_of_week', 'week_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD = featureLabelSplit(CC, target=['pm2_5', 'pm10', 's2_pm2_5', 's2_pm10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, Q = DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_train, Q_train, P_val, Q_val = train_test_spliting(P, Q, test_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "P_train_scale = scaler.fit_transform(P_train)\n",
    "P_val_scale = scaler.transform(P_val)\n",
    "\n",
    "Q_train_scale = scaler.fit_transform(Q_train)\n",
    "Q_val_scale = scaler.transform(Q_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultiOutputRegressor(estimator=Ridge()).fit(P_train_scale, Q_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(P_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_val_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_val_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_lags(df, n_lags):\n",
    "    df_n = df.copy()\n",
    "    for n in range(1, n_lags + 1):\n",
    "        df_n[f\"lag{n}\"] = df_n[\"pm2_5\"].shift(n)\n",
    "    df_n = df_n.iloc[n_lags:]\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_time_lags(KK, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KK.assign(hour=KK.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = KK.assign(hour = KK.index.hour,\n",
    "                 day = KK.index.day,\n",
    "                 month = KK.index.month,\n",
    "                 day_of_week = KK.index.dayofweek,\n",
    "                 week_of_year = KK.index.week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.day_of_week.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_col = 'hour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {f'sin_{time_col}' :lambda x: np.sin(2*np.pi*(x[time_col] - x[time_col].min()) / x[time_col].nunique()),\n",
    "        f'cos_{time_col}' :lambda x: np.cos(2*np.pi*(x[time_col] - x[time_col].min()) / x[time_col].nunique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(2*np.pi*(13-0)/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KK.assign(hour = KK.index.hour, month=KK.).assign(**dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KK.assign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KKKK.agg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KKKK['hour'].apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KKKK[['hour', 'month']].apply(lambda x: np.sin(2*np.pi*(x - x.min()) / x.nunique()), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KK_features = (KK.assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KK['pm2_5'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KK['pm2_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one.groupby(pd.Grouper(key='TimeStamp', freq='1H')).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KK.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_one.TimeStamp.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_mean = channel_one.groupby(channel_one.TimeStamp.dt.month)['pm2_5'].mean().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower, upper = stats.t.interval(alpha=0.95, df=channel_one.groupby(channel_one.TimeStamp.dt.month)['pm2_5'].count()-1, \n",
    "                 loc=channel_one.groupby(channel_one.TimeStamp.dt.month)['pm2_5'].mean(),\n",
    "                scale=channel_one.groupby(channel_one.TimeStamp.dt.month)['pm2_5'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DDD = pd.DataFrame(data=np.array([hour_mean, lower, upper]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_one.groupby(channel_one.TimeStamp.dt.year)['pm2_5'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "\n",
    "ax=sns.boxplot(x=channel_one.TimeStamp.dt.year, y='pm2_5', data=channel_one, orient='v', palette = sns.color_palette(\"deep\", 5))\n",
    "ax.set(ylim=(-50, 600))\n",
    "\n",
    "plt.title('Boxplots of Hourly PM 2.5 by Year', fontsize=16)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('ug/m^3', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "testing[['date', 'pm2_5', 'pm10', 's2_pm2_5', 's2_pm10']].plot(x='date', subplots=True, layout=(2,2),\n",
    "                                                              figsize=(14,10), sharex=False, rot=45)\n",
    "plt.tight_layout(pad=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta = datetime.timedelta(hours=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
